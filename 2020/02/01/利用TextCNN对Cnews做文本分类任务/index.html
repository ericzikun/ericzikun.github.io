<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />

    

    
    <title>利用TextCNN对IMDB做文本分类任务 | Eric’s blog</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="keywords" content="TextCNN,Imdb,文本分类" />
    
    <meta name="description" content="参考博客： imdb预处理 TextCNN模型 1.下载kaggle数据集,并进行文本预处理：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778# 导入相应">
<meta property="og:type" content="article">
<meta property="og:title" content="利用TextCNN对IMDB做文本分类任务">
<meta property="og:url" content="https://ericzikun.github.io/2020/02/01/%E5%88%A9%E7%94%A8TextCNN%E5%AF%B9Cnews%E5%81%9A%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/index.html">
<meta property="og:site_name" content="Eric’s blog">
<meta property="og:description" content="参考博客： imdb预处理 TextCNN模型 1.下载kaggle数据集,并进行文本预处理：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778# 导入相应">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200313225816747.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BvcG9mems=,size_16,color_FFFFFF,t_70#pic_center">
<meta property="article:published_time" content="2020-02-01T13:46:12.000Z">
<meta property="article:modified_time" content="2020-04-12T07:30:16.383Z">
<meta property="article:author" content="Eric kun">
<meta property="article:tag" content="TextCNN">
<meta property="article:tag" content="Imdb">
<meta property="article:tag" content="文本分类">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20200313225816747.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BvcG9mems=,size_16,color_FFFFFF,t_70#pic_center">
    

    
        <link rel="alternate" href="/" title="Eric’s blog" type="application/atom+xml" />
    

    
        <link rel="icon" href="https://pic2.zhimg.com/80/v2-f19e0e0add10a40489cdb8df576a0f7e_qhd.jpg" />
    

    
<link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/libs/titillium-web/styles.css">

    
<link rel="stylesheet" href="/libs/source-code-pro/styles.css">


    
<link rel="stylesheet" href="/css/style.css">


    
<script src="/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
        
<link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">

    
    
        
<link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">

    
    
    
        <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?0d6b4455953d3e1c0917234dfebaa739";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<meta name="generator" content="Hexo 4.2.0"></head>

<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/">主页</a>
                                </li>
                            
                                        <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E5%8D%87%E5%AD%A6%E5%B0%B1%E4%B8%9A/">升学就业</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E5%8D%87%E5%AD%A6%E5%B0%B1%E4%B8%9A/%E4%BF%9D%E7%A0%94/">保研</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%8A%80%E5%B7%A7/">技巧</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%8A%80%E5%B7%A7/Linux/">Linux</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%8A%80%E5%B7%A7/%E6%8A%A5%E9%94%99/">报错</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%8A%80%E5%B7%A7/%E6%8F%90%E5%8D%87%E6%95%88%E7%8E%87/">提升效率</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%8A%80%E5%B7%A7/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/">文本处理</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%8A%80%E5%B7%A7/%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/">论文排版</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E6%A0%88/">技术栈</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E6%A0%88/Java/">Java</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E6%A0%88/Python/">Python</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E6%A0%88/React/">React</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/">决策树</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%84%9F%E7%9F%A5%E6%9C%BA-KNN/">感知机&KNN</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/">朴素贝叶斯</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/">逻辑回归</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/TextCNN/">TextCNN</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Transformer/">Transformer</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8F%AF%E8%A7%86%E5%8C%96/">模型可视化</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E6%96%87%E6%9C%AC%E6%8A%BD%E5%8F%96/">文本抽取</a></li></ul></li></ul>
                                    
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/about/index.html">联系方式</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>


</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>
        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><i class="icon fa fa-angle-right"></i><a class="page-title-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/TextCNN/">TextCNN</a>
    </h1>
</div>

                        <div class="main-body-content">
                            <article id="post-利用TextCNN对Cnews做文本分类任务" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        利用TextCNN对IMDB做文本分类任务
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                <span id="busuanzi_container_page_pv" style='display:none' class="article-date">
  <i class="icon-smile icon"></i> 阅读数：<span id="busuanzi_value_page_pv"></span>次
</span>


    <div class="article-date">
      <i class="fa fa-calendar"></i>
      <a href="/2020/02/01/%E5%88%A9%E7%94%A8TextCNN%E5%AF%B9Cnews%E5%81%9A%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/" class="article-date">
         <time datetime="2020-02-01T13:46:12.000Z" itemprop="datePublished">2020-02-01</time>
      </a>
    </div>


                

                
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/Imdb/" rel="tag">Imdb</a>, <a class="tag-link" href="/tags/TextCNN/" rel="tag">TextCNN</a>, <a class="tag-link" href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/" rel="tag">文本分类</a>
    </div>

                

                

            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <p>参考博客：</p>
<p><a href="https://blog.csdn.net/weixin_44766179/article/details/90286846?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522158373686819724845042300%2522%252C%2522scm%2522%253A%252220140713.130056874..%2522%257D&request_id=158373686819724845042300&biz_id=0&utm_source=distribute.pc_search_result.none-task" target="_blank" rel="noopener">imdb预处理</a></p>
<p><a href="https://blog.csdn.net/asialee_bird/article/details/88813385#1%E3%80%81%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86" target="_blank" rel="noopener">TextCNN模型</a></p>
<h3 id="1-下载kaggle数据集-并进行文本预处理："><a href="#1-下载kaggle数据集-并进行文本预处理：" class="headerlink" title="1.下载kaggle数据集,并进行文本预处理："></a>1.下载kaggle数据集,并进行文本预处理：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入相应的包</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> WordNetLemmatizer</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, LSTM, Embedding, Dropout, Conv1D, MaxPooling1D, Bidirectional</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#　读取数据</span></span><br><span class="line">df1 = pd.read_csv(<span class="string">'word2vec-nlp-tutorial/labeledTrainData.tsv'</span>, sep=<span class="string">'\t'</span>, error_bad_lines=<span class="literal">False</span>)</span><br><span class="line">df2 = pd.read_csv(<span class="string">'word2vec-nlp-tutorial/imdb_master.csv'</span>, encoding=<span class="string">"latin-1"</span>)</span><br><span class="line">df3 = pd.read_csv(<span class="string">'word2vec-nlp-tutorial/testData.tsv'</span>, sep=<span class="string">'\t'</span>, error_bad_lines=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">df2 = df2.drop([<span class="string">'Unnamed: 0'</span>,<span class="string">'type'</span>,<span class="string">'file'</span>],axis=<span class="number">1</span>)</span><br><span class="line">df2.columns = [<span class="string">"review"</span>,<span class="string">"sentiment"</span>]</span><br><span class="line">df2 = df2[df2.sentiment != <span class="string">'unsup'</span>]</span><br><span class="line">df2[<span class="string">'sentiment'</span>] = df2[<span class="string">'sentiment'</span>].map(&#123;<span class="string">'pos'</span>: <span class="number">1</span>, <span class="string">'neg'</span>: <span class="number">0</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并数据</span></span><br><span class="line">df = pd.concat([df1, df2]).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">train_texts = df.review</span><br><span class="line">train_labels = df.sentiment</span><br><span class="line">test_texts = df3.review</span><br><span class="line"></span><br><span class="line"><span class="comment"># 英文缩写替换</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">replace_abbreviations</span><span class="params">(text)</span>:</span></span><br><span class="line">    texts = []</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> text:</span><br><span class="line">        item = item.lower().replace(<span class="string">"it's"</span>, <span class="string">"it is"</span>).replace(<span class="string">"i'm"</span>, <span class="string">"i am"</span>).replace(<span class="string">"he's"</span>, <span class="string">"he is"</span>).replace(<span class="string">"she's"</span>, <span class="string">"she is"</span>)\</span><br><span class="line">            .replace(<span class="string">"we're"</span>, <span class="string">"we are"</span>).replace(<span class="string">"they're"</span>, <span class="string">"they are"</span>).replace(<span class="string">"you're"</span>, <span class="string">"you are"</span>).replace(<span class="string">"that's"</span>, <span class="string">"that is"</span>)\</span><br><span class="line">            .replace(<span class="string">"this's"</span>, <span class="string">"this is"</span>).replace(<span class="string">"can't"</span>, <span class="string">"can not"</span>).replace(<span class="string">"don't"</span>, <span class="string">"do not"</span>).replace(<span class="string">"doesn't"</span>, <span class="string">"does not"</span>)\</span><br><span class="line">            .replace(<span class="string">"we've"</span>, <span class="string">"we have"</span>).replace(<span class="string">"i've"</span>, <span class="string">" i have"</span>).replace(<span class="string">"isn't"</span>, <span class="string">"is not"</span>).replace(<span class="string">"won't"</span>, <span class="string">"will not"</span>)\</span><br><span class="line">            .replace(<span class="string">"hasn't"</span>, <span class="string">"has not"</span>).replace(<span class="string">"wasn't"</span>, <span class="string">"was not"</span>).replace(<span class="string">"weren't"</span>, <span class="string">"were not"</span>).replace(<span class="string">"let's"</span>, <span class="string">"let us"</span>)\</span><br><span class="line">            .replace(<span class="string">"didn't"</span>, <span class="string">"did not"</span>).replace(<span class="string">"hadn't"</span>, <span class="string">"had not"</span>).replace(<span class="string">"waht's"</span>, <span class="string">"what is"</span>).replace(<span class="string">"couldn't"</span>, <span class="string">"could not"</span>)\</span><br><span class="line">            .replace(<span class="string">"you'll"</span>, <span class="string">"you will"</span>).replace(<span class="string">"you've"</span>, <span class="string">"you have"</span>)</span><br><span class="line">    </span><br><span class="line">        item = item.replace(<span class="string">"'s"</span>, <span class="string">""</span>)</span><br><span class="line">        texts.append(item)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> texts</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除标点符号及其它字符</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clear_review</span><span class="params">(text)</span>:</span></span><br><span class="line">    texts = []</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> text:</span><br><span class="line">        item = item.replace(<span class="string">"&lt;br /&gt;&lt;br /&gt;"</span>, <span class="string">""</span>)</span><br><span class="line">        item = re.sub(<span class="string">"[^a-zA-Z]"</span>, <span class="string">" "</span>, item.lower())</span><br><span class="line">        texts.append(<span class="string">" "</span>.join(item.split()))</span><br><span class="line">    <span class="keyword">return</span> texts</span><br><span class="line"></span><br><span class="line"><span class="comment"># ＃　删除停用词　＋　词形还原</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stemed_words</span><span class="params">(text)</span>:</span></span><br><span class="line">    stop_words = stopwords.words(<span class="string">"english"</span>)</span><br><span class="line">    lemma = WordNetLemmatizer()</span><br><span class="line">    texts = []</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> text:</span><br><span class="line">        words = [lemma.lemmatize(w, pos=<span class="string">'v'</span>) <span class="keyword">for</span> w <span class="keyword">in</span> item.split() <span class="keyword">if</span> w <span class="keyword">not</span> <span class="keyword">in</span> stop_words]</span><br><span class="line">        texts.append(<span class="string">" "</span>.join(words))</span><br><span class="line">    <span class="keyword">return</span> texts</span><br><span class="line">            </span><br><span class="line"><span class="comment"># ＃　文本预处理</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span><span class="params">(text)</span>:</span></span><br><span class="line">    text = replace_abbreviations(text)</span><br><span class="line">    text = clear_review(text)</span><br><span class="line">    text = stemed_words(text)    </span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line">  </span><br><span class="line">train_texts = preprocess(train_texts)</span><br><span class="line">test_texts = preprocess(test_texts)</span><br></pre></td></tr></table></figure>

<h3 id="2-token编码、padding操作、切分数据集"><a href="#2-token编码、padding操作、切分数据集" class="headerlink" title="2.token编码、padding操作、切分数据集"></a>2.token编码、padding操作、切分数据集</h3><p>也就是建立onehot向量，这里只取频率排行前6000个单词构建词典，令max_features = 6000; 然后将每个样本（句子）定为长度130（不够长补0，多余截断）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">max_features = <span class="number">6000</span></span><br><span class="line">texts = train_texts + test_texts</span><br><span class="line"><span class="comment"># 转换为onehot向量，num_words：保留词频前max_features的词汇，其他词删去。仅num_words-1保留最常用的词。</span></span><br><span class="line">tok = Tokenizer(num_words=max_features)</span><br><span class="line">tok.fit_on_texts(texts)</span><br><span class="line">vocab = tok.word_index</span><br><span class="line"><span class="comment"># 将文本按照词典编号的方式进行编码</span></span><br><span class="line">list_tok = tok.texts_to_sequences(texts)</span><br><span class="line"></span><br><span class="line"><span class="comment">#对每个样本最大长度做限制，定为130，其余补0</span></span><br><span class="line">maxlen = <span class="number">130</span></span><br><span class="line">seq_tok = pad_sequences(list_tok, maxlen=maxlen)</span><br><span class="line"></span><br><span class="line">x_train = seq_tok[:len(train_texts)]  <span class="comment">#只取到train_texts的样本</span></span><br><span class="line">y_train = train_labels</span><br><span class="line"></span><br><span class="line">embed_size = <span class="number">128</span> <span class="comment">#此为通过embedding矩阵乘法，我们想让一个样本（句子）中每个单词压缩成的向量维度</span></span><br><span class="line"></span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x_train,y_train) <span class="comment">#切分训练、测试集</span></span><br></pre></td></tr></table></figure>

<p>3.整理好数据后，采用TensorFlow中的CNN模型或者TextCNN模型进行训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> jieba </span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers.merge <span class="keyword">import</span> concatenate </span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> to_categorical </span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.text <span class="keyword">import</span> Tokenizer </span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences </span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> * </span><br><span class="line"><span class="keyword">from</span> keras.layers.embeddings <span class="keyword">import</span> Embedding </span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv1D, MaxPooling1D, Flatten, Dropout, Dense, Input, Lambda,BatchNormalization </span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, f1_score </span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment">#构建TextCNN模型</span></span><br><span class="line"><span class="comment">#模型结构：词嵌入-卷积池化*3-拼接-全连接-dropout-全连接</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">TextCNN_model_1</span><span class="params">(x_train_padded_seqs,y_train,x_test_padded_seqs,y_test)</span>:</span></span><br><span class="line">    main_input = Input(shape=(<span class="number">130</span>,), dtype=<span class="string">'float64'</span>)</span><br><span class="line">    <span class="comment"># 词嵌入（使用预训练的词向量）</span></span><br><span class="line">    embedder = Embedding(len(vocab) + <span class="number">1</span>, <span class="number">300</span>, input_length=<span class="number">130</span>, trainable=<span class="literal">False</span>)</span><br><span class="line">    embed = embedder(main_input)</span><br><span class="line">    <span class="comment"># 词窗大小分别为3,4,5</span></span><br><span class="line">    cnn1 = Conv1D(<span class="number">256</span>, <span class="number">3</span>, padding=<span class="string">'same'</span>, strides=<span class="number">1</span>, activation=<span class="string">'relu'</span>)(embed)</span><br><span class="line">    cnn1 = MaxPooling1D(pool_size=<span class="number">128</span>)(cnn1)</span><br><span class="line">    cnn2 = Conv1D(<span class="number">256</span>, <span class="number">4</span>, padding=<span class="string">'same'</span>, strides=<span class="number">1</span>, activation=<span class="string">'relu'</span>)(embed)</span><br><span class="line">    cnn2 = MaxPooling1D(pool_size=<span class="number">127</span>)(cnn2)</span><br><span class="line">    cnn3 = Conv1D(<span class="number">256</span>, <span class="number">5</span>, padding=<span class="string">'same'</span>, strides=<span class="number">1</span>, activation=<span class="string">'relu'</span>)(embed)</span><br><span class="line">    cnn3 = MaxPooling1D(pool_size=<span class="number">126</span>)(cnn3)</span><br><span class="line">    <span class="comment"># 合并三个模型的输出向量</span></span><br><span class="line">    cnn = concatenate([cnn1, cnn2, cnn3], axis=<span class="number">-1</span>)</span><br><span class="line">    flat = Flatten()(cnn)</span><br><span class="line">    drop = Dropout(<span class="number">0.2</span>)(flat)</span><br><span class="line">    main_output = Dense(<span class="number">2</span>, activation=<span class="string">'softmax'</span>)(drop)</span><br><span class="line">    model = Model(inputs=main_input, outputs=main_output)</span><br><span class="line">    model.compile(loss=<span class="string">'categorical_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"> </span><br><span class="line">    one_hot_labels = keras.utils.to_categorical(y_train, num_classes=<span class="number">2</span>)  <span class="comment"># 将标签转换为one-hot编码</span></span><br><span class="line">    model.fit(x_train_padded_seqs, one_hot_labels, batch_size=<span class="number">800</span>, epochs=<span class="number">10</span>)</span><br><span class="line">    <span class="comment">#y_test_onehot = keras.utils.to_categorical(y_test, num_classes=3)  # 将标签转换为one-hot编码</span></span><br><span class="line">    result = model.predict(x_test_padded_seqs)  <span class="comment"># 预测样本属于每个类别的概率</span></span><br><span class="line">    result_labels = np.argmax(result, axis=<span class="number">1</span>)  <span class="comment"># 获得最大概率对应的标签</span></span><br><span class="line"><span class="comment">#     y_predict = list(map(str, result_labels))</span></span><br><span class="line"><span class="comment">#     print('准确率', metrics.accuracy_score(y_test, y_predict))</span></span><br><span class="line"><span class="comment">#     print('平均f1-score:', metrics.f1_score(y_test, y_predict, average='weighted'))</span></span><br><span class="line">    print(<span class="string">'准确率'</span>, accuracy_score(y_test, result_labels))</span><br><span class="line">    print(<span class="string">'平均f1-score:'</span>, f1_score(y_test, result_labels, average=<span class="string">'weighted'</span>))</span><br></pre></td></tr></table></figure>

<h3 id="4-训练结果-在colab上训练-："><a href="#4-训练结果-在colab上训练-：" class="headerlink" title="4.训练结果(在colab上训练)："></a>4.训练结果(在colab上训练)：</h3><p><img src="https://img-blog.csdnimg.cn/20200313225139123.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BvcG9mems=,size_16,color_FFFFFF,t_70" alt></p>
<p><a href="https://blog.csdn.net/asialee_bird/article/details/88813385#1、读取数据集" target="_blank" rel="noopener"></a></p>
<img src="https://img-blog.csdnimg.cn/20200313225417151.png#pic_center#pic_center = 200x300" style="zoom:50%;">

<img src="https://img-blog.csdnimg.cn/20200313225437275.png#pic_center" style="zoom:50%;">

<h3 id="5-模型理解："><a href="#5-模型理解：" class="headerlink" title="5.模型理解："></a>5.模型理解：</h3><p>这里可以通过model.summary或者keras中的plot_model来输出模型整体结构，帮助理解，<a href="https://blog.csdn.net/popofzk/article/details/104689669" target="_blank" rel="noopener">plot_model报错踩坑</a></p>
<p>尤其是像这种有concatenate函数合并的结构，图形可视化很直观，方便学习。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">main_input = Input(shape=(<span class="number">50</span>,), dtype=<span class="string">'float64'</span>)</span><br><span class="line"><span class="comment"># 词嵌入（使用预训练的词向量）</span></span><br><span class="line">embedder = Embedding(<span class="number">10000</span> + <span class="number">1</span>, <span class="number">300</span>, input_length=<span class="number">50</span>, trainable=<span class="literal">False</span>)</span><br><span class="line">embed = embedder(main_input)</span><br><span class="line"><span class="comment"># 词窗大小分别为3,4,5</span></span><br><span class="line">cnn1 = Conv1D(<span class="number">256</span>, <span class="number">3</span>, padding=<span class="string">'same'</span>, strides=<span class="number">1</span>, activation=<span class="string">'relu'</span>)(embed)</span><br><span class="line">cnn1 = MaxPooling1D(pool_size=<span class="number">48</span>)(cnn1)</span><br><span class="line">cnn2 = Conv1D(<span class="number">256</span>, <span class="number">4</span>, padding=<span class="string">'same'</span>, strides=<span class="number">1</span>, activation=<span class="string">'relu'</span>)(embed)</span><br><span class="line">cnn2 = MaxPooling1D(pool_size=<span class="number">47</span>)(cnn2)</span><br><span class="line">cnn3 = Conv1D(<span class="number">256</span>, <span class="number">5</span>, padding=<span class="string">'same'</span>, strides=<span class="number">1</span>, activation=<span class="string">'relu'</span>)(embed)</span><br><span class="line">cnn3 = MaxPooling1D(pool_size=<span class="number">46</span>)(cnn3)</span><br><span class="line"><span class="comment"># 合并三个模型的输出向量</span></span><br><span class="line">cnn = concatenate([cnn1, cnn2, cnn3], axis=<span class="number">-1</span>)</span><br><span class="line">flat = Flatten()(cnn)</span><br><span class="line">drop = Dropout(<span class="number">0.2</span>)(flat)</span><br><span class="line">main_output = Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>)(drop)</span><br><span class="line">model = Model(inputs=main_input, outputs=main_output)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> plot_model</span><br><span class="line"><span class="keyword">import</span> pydot</span><br><span class="line">plot_model(model,to_file=<span class="string">'TextCNNmodel2.png'</span>,show_shapes=<span class="literal">True</span>,show_layer_names=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>



<img src="https://img-blog.csdnimg.cn/20200313225735218.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BvcG9mems=,size_16,color_FFFFFF,t_70#pic_center" style="zoom:50%;">

<p>​                                                                                            <center><strong>图一</strong></center></p>
<img src="https://img-blog.csdnimg.cn/20200313225816747.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BvcG9mems=,size_16,color_FFFFFF,t_70#pic_center" style="zoom:50%;">

<p>​                                                                                            <center><strong>图二</strong></center></p>
<img src="https://img-blog.csdnimg.cn/20200313225852804.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BvcG9mems=,size_16,color_FFFFFF,t_70#pic_center" style="zoom:50%;">

<p>​                                                                                            <center><strong>图三</strong></center></p>
<p>​        相比于图像领域的CNN，文本处理中的TextCNN有一定的差异，第一是在维度上面，由图二（普通CNN）：每一个<strong>卷积核宽度就是每个词向量的长度</strong>，从上向下滑动，没有图像领域中的横向滑动，故调用Conv1D，每次滑动几个单词就是卷积核的高度，如图三：三种不同高度的卷积核，能够每次读取不同相邻个数的单词，这里有点像n-gram的感觉，不同高度的卷积核能够提取不同的特征，而这些特征恰好能够<strong>体现词与词之间的关联</strong>，</p>
<p>​        图一中：每一层的第一个维度是None，这里的None就是你的batchsize，每次处理的样本个数，因为这个参数是在model.fit中定义，所以这里显示none；</p>
<ol>
<li><p><strong>输入层</strong>：维度为batchsize $\times$ input_length ,input_length就是我们的一个句子的长度，就像图二中 输入层左边从上到下就是一句话，一个句子就是一个样本。</p>
</li>
<li><p><strong>embedding层</strong>：将batchsize $\times$ input_length输入embedding层中，embedding层的参数300，就是我们想要每个词向量维度变成的长度，为什么要这么做呢？因为如果每个词都是用onehot向量，那么整个单词词典有多长，词向量就有多长，这样第一：计算能力要求会非常高，当词典无限大的时候也没法办了，第二：onehot向量只体现了词频，无法体现语义上的含义，我们更希望采用一个低维的向量来刻画单词本身，embedding的作用就是降维，当输入之后，embedding层用input_length $\times$(len(vocab)+1) 来与 (len(vocab)+1)$\times$300相乘，就将每个句子变成了：input_length $\times$300的矩阵，从而实现词向量的降维，而这一层刚开始就是起到初始化的作用。这里不同于word2vec的是：word2vec的目的是训练词向量，而embedding是训练词向量的一种方式，或者说在整个模型任务达到收敛后，embedding层训练出来的词向量就是切合任务需求的（这里模型后面层可能是二分类，也可能是多分类或者等等任务）。</p>
</li>
<li><p><strong>卷积层</strong>：这里TextCNN设置了3、4、5的三个不同高度的卷积核，每次滑动的时候进行向量乘法，padding选为same就是让卷积之后得到的长度和原来长度（50）一致，举例：当卷积核高度为3时，步长为1向下滑动，每滑动一次生成一个向量值，那么要保证前后长度都为50的话，就要在原来的50长度下面加2个padding值。</p>
</li>
<li><p><strong>池化层</strong>：参数中如果不特别设定步长，keras默认和池化大小（pool_size）相同，定为48就是因为没算padding的0.</p>
</li>
</ol>

        </div>
        <footer class="article-footer">
            



    <a data-url="https://ericzikun.github.io/2020/02/01/%E5%88%A9%E7%94%A8TextCNN%E5%AF%B9Cnews%E5%81%9A%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/" data-id="ck8wqbn27000dyzt6h95mek4e" class="article-share-link"><i class="fa fa-share"></i>分享到</a>
<script>
    (function ($) {
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

        </footer>
    </div>
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "author": {
            "@type": "Person",
            "name": "Eric kun"
        },
        "headline": "利用TextCNN对IMDB做文本分类任务",
        "image": "https://ericzikun.github.iohttps://img-blog.csdnimg.cn/20200313225816747.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BvcG9mems=,size_16,color_FFFFFF,t_70#pic_center",
        "keywords": "TextCNN Imdb 文本分类",
        "genre": "深度学习 TextCNN",
        "datePublished": "2020-02-01",
        "dateCreated": "2020-02-01",
        "dateModified": "2020-04-12",
        "url": "https://ericzikun.github.io/2020/02/01/利用TextCNN对Cnews做文本分类任务/",
        "description": "参考博客：
imdb预处理
TextCNN模型
1.下载kaggle数据集,并进行文本预处理：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778# 导入相应",
        "wordCount": 1730
    }
</script>

</article>

    <section id="comments">
    
        
    <!-- Valine -->
    <div class="vcomments"></div>


    
    </section>



                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>关注我 :</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="twitter" href="https://www.zhihu.com/people/feng-kun-33-65" target="_blank" rel="noopener">
                        <i class="icon fa fa-twitter"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="facebook" href="/" target="_blank" rel="noopener">
                        <i class="icon fa fa-facebook"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="stack-overflow" href="/" target="_blank" rel="noopener">
                        <i class="icon fa fa-stack-overflow"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/ericzikun" target="_blank" rel="noopener">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="weibo" href="/" target="_blank" rel="noopener">
                        <i class="icon fa fa-weibo"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="rss" href="/" target="_blank" rel="noopener">
                        <i class="icon fa fa-rss"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2020/02/08/%E6%8F%90%E5%8D%87%E6%95%88%E7%8E%87%E5%B0%8F%E6%8A%80%E5%B7%A7/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">下一篇</strong>
        <p class="article-nav-title">
        
            提升效率集锦
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2019/12/22/Mactex%E5%86%99%E8%AE%BA%E6%96%87/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">上一篇</strong>
        <p class="article-nav-title">Mactex写论文</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                
  <div class="widget-wrap widget-list">
      <h3 class="widget-title"></h3>
      <div class="widget">
        <b>联系方式：847473488@qq.com<br/>
        知乎：ERICK</b>
          <!--这里添加你要写的内容-->
      </div>
  </div>

            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/Imdb/" style="font-size: 10px;">Imdb</a> <a href="/tags/KNN/" style="font-size: 10px;">KNN</a> <a href="/tags/Keras/" style="font-size: 10px;">Keras</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/Mac/" style="font-size: 20px;">Mac</a> <a href="/tags/NLP/" style="font-size: 10px;">NLP</a> <a href="/tags/Tensorflow/" style="font-size: 10px;">Tensorflow</a> <a href="/tags/TextCNN/" style="font-size: 10px;">TextCNN</a> <a href="/tags/Textrank/" style="font-size: 10px;">Textrank</a> <a href="/tags/Transformer/" style="font-size: 10px;">Transformer</a> <a href="/tags/%E4%BF%9D%E7%A0%94/" style="font-size: 10px;">保研</a> <a href="/tags/%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8A%BD%E5%8F%96/" style="font-size: 10px;">关键词抽取</a> <a href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/" style="font-size: 10px;">决策树</a> <a href="/tags/%E5%8D%87%E5%AD%A6%EF%BC%8C%E8%AF%BB%E7%A0%94/" style="font-size: 10px;">升学，读研</a> <a href="/tags/%E5%AD%A6%E6%9C%AF/" style="font-size: 16.67px;">学术</a> <a href="/tags/%E6%84%9F%E7%9F%A5%E6%9C%BA/" style="font-size: 10px;">感知机</a> <a href="/tags/%E6%8A%A5%E9%94%99/" style="font-size: 13.33px;">报错</a> <a href="/tags/%E6%95%88%E7%8E%87/" style="font-size: 20px;">效率</a> <a href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/" style="font-size: 10px;">文本分类</a> <a href="/tags/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/" style="font-size: 10px;">文本处理</a> <a href="/tags/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/" style="font-size: 10px;">朴素贝叶斯</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">机器学习</a> <a href="/tags/%E6%A0%BC%E5%BC%8F%E5%8C%96%E6%96%87%E6%9C%AC/" style="font-size: 10px;">格式化文本</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">深度学习</a> <a href="/tags/%E6%BA%90%E7%A0%81/" style="font-size: 10px;">源码</a> <a href="/tags/%E7%BB%88%E7%AB%AF/" style="font-size: 10px;">终端</a> <a href="/tags/%E7%BB%8F%E9%AA%8C/" style="font-size: 10px;">经验</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" style="font-size: 16.67px;">统计学习方法</a> <a href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/" style="font-size: 10px;">自然语言处理</a> <a href="/tags/%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/" style="font-size: 10px;">论文排版</a> <a href="/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/" style="font-size: 10px;">逻辑回归</a> <a href="/tags/%E9%A2%84%E5%A4%84%E7%90%86/" style="font-size: 10px;">预处理</a>
        </div>
    </div>


            
                

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">最新文章</h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2020/04/11/Transformer-%E5%8E%9F%E7%90%86-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E6%80%BB%E7%BB%93-Tensorflow%E5%AE%98%E6%96%B9%E6%BA%90%E7%A0%81/" class="thumbnail">
    
    
        <span style="background-image:url(https://img-blog.csdnimg.cn/20200411142658336.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BvcG9mems=,size_16,color_FFFFFF,t_70#pic_center)" alt="Transformer 原理+源码分析总结(Tensorflow官方源码)" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Transformer/">Transformer</a></p>
                            <p class="item-title"><a href="/2020/04/11/Transformer-%E5%8E%9F%E7%90%86-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E6%80%BB%E7%BB%93-Tensorflow%E5%AE%98%E6%96%B9%E6%BA%90%E7%A0%81/" class="title">Transformer 原理+源码分析总结(Tensorflow官方源码)</a></p>
                            <p class="item-date"><time datetime="2020-04-11T09:49:11.000Z" itemprop="datePublished">2020-04-11</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2020/04/10/%E7%BB%88%E7%AB%AF%E5%91%BD%E4%BB%A4%E5%8F%8AColab%E7%99%BD%E5%AB%96%E5%BF%85%E5%A4%87/" class="thumbnail">
    
    
        <span style="background-image:url(https://img-blog.csdnimg.cn/20200410192110723.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BvcG9mems=,size_16,color_FFFFFF,t_70)" alt="终端命令及Colab白嫖必备" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/%E6%8A%80%E5%B7%A7/">技巧</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/%E6%8A%80%E5%B7%A7/Linux/">Linux</a></p>
                            <p class="item-title"><a href="/2020/04/10/%E7%BB%88%E7%AB%AF%E5%91%BD%E4%BB%A4%E5%8F%8AColab%E7%99%BD%E5%AB%96%E5%BF%85%E5%A4%87/" class="title">终端命令及Colab白嫖必备</a></p>
                            <p class="item-date"><time datetime="2020-04-10T15:24:35.000Z" itemprop="datePublished">2020-04-10</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2020/04/09/%E4%BF%9D%E7%A0%94%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/" class="thumbnail">
    
    
        <span style="background-image:url(http://img4.imgtn.bdimg.com/it/u=2273282424,2294415740&fm=11&gp=0.jpg)" alt="保研经验总结" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/%E5%8D%87%E5%AD%A6%E5%B0%B1%E4%B8%9A/">升学就业</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/%E5%8D%87%E5%AD%A6%E5%B0%B1%E4%B8%9A/%E4%BF%9D%E7%A0%94/">保研</a></p>
                            <p class="item-title"><a href="/2020/04/09/%E4%BF%9D%E7%A0%94%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/" class="title">保研经验总结</a></p>
                            <p class="item-date"><time datetime="2020-04-09T12:40:45.000Z" itemprop="datePublished">2020-04-09</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2020/04/08/Mac%E5%AE%89%E8%A3%85gensim%E8%B8%A9%E5%9D%91/" class="thumbnail">
    
    
        <span style="background-image:url(https://img-blog.csdnimg.cn/20200225104733764.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BvcG9mems=,size_16,color_FFFFFF,t_70)" alt="Mac安装gensim踩坑" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/%E6%8A%80%E5%B7%A7/">技巧</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/%E6%8A%80%E5%B7%A7/%E6%8A%A5%E9%94%99/">报错</a></p>
                            <p class="item-title"><a href="/2020/04/08/Mac%E5%AE%89%E8%A3%85gensim%E8%B8%A9%E5%9D%91/" class="title">Mac安装gensim踩坑</a></p>
                            <p class="item-date"><time datetime="2020-04-08T02:22:27.000Z" itemprop="datePublished">2020-04-08</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2020/04/08/mac%E5%AE%89%E8%A3%85cnpm%E8%B8%A9%E5%9D%91/" class="thumbnail">
    
    
        <span style="background-image:url(https://img-blog.csdnimg.cn/20200225104733764.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BvcG9mems=,size_16,color_FFFFFF,t_70)" alt="mac安装cnpm踩坑" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/%E6%8A%80%E5%B7%A7/">技巧</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/%E6%8A%80%E5%B7%A7/%E6%8A%A5%E9%94%99/">报错</a></p>
                            <p class="item-title"><a href="/2020/04/08/mac%E5%AE%89%E8%A3%85cnpm%E8%B8%A9%E5%9D%91/" class="title">mac安装cnpm踩坑</a></p>
                            <p class="item-date"><time datetime="2020-04-08T02:21:50.000Z" itemprop="datePublished">2020-04-08</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">四月 2020</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">二月 2020</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">十二月 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">十一月 2019</a><span class="archive-list-count">4</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">链接</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io" target="_blank" rel="noopener">Hexo</a>
                    </li>
                
                    <li>
                        <a href="https://blog.csdn.net/popofzk" target="_blank" rel="noopener">CSDN</a>
                    </li>
                
                    <li>
                        <a href="https://www.zhihu.com/people/feng-kun-33-65" target="_blank" rel="noopener">知乎</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
        
    </div>
</aside>

                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2020 Eric kun</p>
                
                <p>Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="https://github.com/ppoffice" target="_blank">PPOffice</a></p>
                
            </div>
            <div class="parent">
              <div class="child">
                <span id="busuanzi_container_site_pv">
                  访问量<span id="busuanzi_value_site_pv"></span>次
                </span>
                <span class="post-meta-divider">|</span>
                <span id="busuanzi_container_site_uv" style='display:none'>
                  访客数<span id="busuanzi_value_site_uv"></span>人
                </span>
                <script async="" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
              </div>
            </div>
            <div class="footer-plugins">
              
    


            </div>
        </div>
    </div>
    <style>
      .parent {
        position: relative;
      }
      .child {
        position: absolute;
        left: 50%;
        top: 50%;
        transform: translate(-50%, -50%);
      }
    </style>  
</footer>

        
    
    <script src="//unpkg.com/valine"></script>
    <script>
        var GUEST = ['nick','mail','link'];
        var meta = '';
        meta = meta.split(',').filter(function (item) {
            return GUEST.indexOf(item)>-1;
        });
        var avatarcdn = 'https://gravatar.loli.net/avatar/' == true;
        new Valine({
            el: '.vcomments',
            notify: "",
            verify: "",
            appId: "tx6zs0UB1yRovubWAD3heyoM-gzGzoHsz",
            appKey: "8SJzl4MBSSjcdEESUaALKRXk",
            placeholder: "Just Do It",
            avatar:"identicon",
            recordIP:"",
            visitor: ""
        });
    </script>





    
        
<script src="/libs/lightgallery/js/lightgallery.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-pager.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-zoom.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-hash.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-share.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-video.min.js"></script>

    
    
        
<script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>

    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML.js"></script>

    

    



<!-- Custom Scripts -->

<script src="/js/main.js"></script>


    </div>
</body>
</html>
